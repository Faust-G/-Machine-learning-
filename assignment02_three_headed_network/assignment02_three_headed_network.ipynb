{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJpwRAWulELd"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bHW6hfglELf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365a5446-e8a0-497a-a225-3fe978f7d4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0      5      0 --:--:--  0:00:02 --:--:--     5\n",
            "100   342  100   342    0     0    107      0  0:00:03  0:00:03 --:--:--   107\n",
            "100  119M  100  119M    0     0  15.1M      0  0:00:07  0:00:07 --:--:-- 30.5M\n",
            "Train_rev1.csv\n",
            "--2023-02-22 07:54:08--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py’\n",
            "\n",
            "network.py          100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-22 07:54:08 (25.2 MB/s) - ‘network.py’ saved [1469/1469]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwN72gd4ycOA"
      },
      "outputs": [],
      "source": [
        "# run this cell if you have downloaded the dataset on the seminar\n",
        "# data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUWkpd7PycOQ",
        "outputId": "cafa01e6-27ca-46e9-e295-ecfa4a1075c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:26, 9083.32it/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWxxkfvIlELn",
        "outputId": "19778661-8b3b-46a1-9f42-90cd880e6e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "515ccf5f-5788-491e-b9ac-c2da8724c285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "69002887-eeea-42e3-947b-62d1a7b97b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "c59e9ae4-81c7-4eb5-9dbe-bc1b28baed5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "db1ea832-dec3-4fc4-ddbc-e7d6e2019e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N9TAw5plELy"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_3zjb0slELz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rlrZAKPlEL0"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUNrzl1QlEL0"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6RnkOeklEL1"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MalstAz7lEL3"
      },
      "outputs": [],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brmWjioAlEL3"
      },
      "outputs": [],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7zx5cbQlEL4",
        "outputId": "26279e3c-5663-4baa-bf8d-8e986ebc47b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Title': array([[11439,  1467,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1],\n",
              "        [18664,  7252,   195, 24093, 18670, 12351, 13242,   195, 12724,\n",
              "           195, 10720],\n",
              "        [26688, 10702,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1]], dtype=int32),\n",
              " 'FullDescription': array([[30411, 26324, 33079, ...,     1,     1,     1],\n",
              "        [18664,  7252,   195, ...,   195,     0,    80],\n",
              "        [26688, 10702, 10364, ...,     1,     1,     1]], dtype=int32),\n",
              " 'Categorical': array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od8VhwoWlEL5"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBbpz1FulEL5",
        "outputId": "e9ee674d-88f6-4f38-eafe-5386382c4fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0493],\n",
              "        [0.1251],\n",
              "        [0.0742]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI9se5ZwlEL6",
        "outputId": "f0721a84-ba7e-4e65-b1ac-56f69694f2cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 653)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yfEA6bYlEL6"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BadymY-lEL7",
        "outputId": "ce48efe5-ee49-4083-89ab-ca6e3960fe21"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from IPython.display import clear_output\n",
        "# from random import sample\n",
        "\n",
        "# epochs = 1\n",
        "\n",
        "# model = simple_model\n",
        "# opt = torch.optim.Adam(model.parameters())\n",
        "# loss_func = nn.MSELoss()\n",
        "\n",
        "# history = []\n",
        "# for epoch_num in range(epochs):\n",
        "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "#         # Preprocessing the batch data and target\n",
        "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "#         target = torch.tensor(target)\n",
        "\n",
        "\n",
        "#         predictions = model(batch)\n",
        "#         predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "#         # train with backprop\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n",
        "#         # <YOUR CODE HERE>\n",
        "\n",
        "#         history.append(loss.data.numpy())\n",
        "#         if (idx+1)%10==0:\n",
        "#             clear_output(True)\n",
        "#             plt.plot(history,label='loss')\n",
        "#             plt.legend()\n",
        "#             plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh62pPEMlEL7"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6TVJjk9WpGqS",
        "outputId": "86dbdf73-c218-42a7-d169-147d259d7671"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "G49RQQsQlEL8"
      },
      "outputs": [],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "76yFGHxDlEL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32dca93a-02a6-438e-e4cc-d9ceb51d13ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "GJMkKouOlEL9"
      },
      "outputs": [],
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "    concat_number_of_features=600 \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "R9QUlPhIlEL-"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "d3zMv71ulEL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47bbfbb-c8e9-4e27-d997-906d33736732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3okvuEbvlEL_"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "LMmdgQkRlEL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e91938bf-3b79-4028-ddfa-ca36a144eddb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "epochs = 1\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "model.train()\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        batch = [\n",
        "            torch.tensor(batch['Title'], dtype=torch.long, device = device),\n",
        "            torch.tensor(batch['FullDescription'], dtype=torch.long, device = device),\n",
        "            torch.tensor(batch['Categorical'], device = device)]\n",
        "        target = torch.tensor(target, device = device)\n",
        "\n",
        "\n",
        "        predictions = model(batch)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)\n",
        "\n",
        "        \n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        \n",
        "\n",
        "        history.append(loss.cpu().data.numpy())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfgcSDa7lEMA"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "UOwE_zXklEMA"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "model = model.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ngAnokamlEMA"
      },
      "outputs": [],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "zGTmoFWNlEMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ce7a7a-23f3-4407-8304-f43cfaeb2219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:11,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.13789\n",
            "Mean absolute error: 0.28649\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkCnqfFClEMB"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}