{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"execution":{"iopub.execute_input":"2024-07-28T18:42:48.849635Z","iopub.status.busy":"2024-07-28T18:42:48.849223Z","iopub.status.idle":"2024-07-28T18:43:31.777430Z","shell.execute_reply":"2024-07-28T18:43:31.776305Z","shell.execute_reply.started":"2024-07-28T18:42:48.849581Z"},"id":"Adw1YpnG08W-","jupyter":{"outputs_hidden":true},"outputId":"c97196a7-69fe-4283-fa4d-a1ce0790522f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: torchdata in /opt/conda/lib/python3.10/site-packages (0.7.1)\n","Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata) (1.26.18)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.32.3)\n","Requirement already satisfied: torch>=2 in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.1.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (1.13.0)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (2024.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2->torchdata) (2.1.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install torchdata"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-28T22:12:32.579936Z","iopub.status.busy":"2024-07-28T22:12:32.579243Z","iopub.status.idle":"2024-07-28T22:12:51.858522Z","shell.execute_reply":"2024-07-28T22:12:51.857532Z","shell.execute_reply.started":"2024-07-28T22:12:32.579877Z"},"id":"T9EOXdAM3bpG","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-28 22:12:39.992859: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-28 22:12:39.992976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-28 22:12:40.121839: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, AutoModelForCausalLM, DataCollatorForTokenClassification, TrainingArguments, Trainer, GenerationConfig\n","# from datasets import load_dataset\n","import torch\n","from torchdata.datapipes.iter import IterableWrapper\n","import random\n","\n","from torch.utils.data import Dataset\n","from transformers import AutoTokenizer\n","from tqdm import tqdm\n","import json\n","\n","random_state = 33\n","random.seed(random_state)\n","torch.random.manual_seed(random_state)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:12:51.861305Z","iopub.status.busy":"2024-07-28T22:12:51.860542Z","iopub.status.idle":"2024-07-28T22:13:28.302993Z","shell.execute_reply":"2024-07-28T22:13:28.302163Z","shell.execute_reply.started":"2024-07-28T22:12:51.861270Z"},"id":"U60t53N5JSfB","trusted":true},"outputs":[],"source":["with open('/kaggle/input/arithmetic/_n_20_m_20_examples_20000000.txt') as f:\n","    lines = f.readlines()\n","lines = [i[:-1] for i in lines]\n","random.shuffle(lines)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:13:28.304554Z","iopub.status.busy":"2024-07-28T22:13:28.304198Z","iopub.status.idle":"2024-07-28T22:14:29.921326Z","shell.execute_reply":"2024-07-28T22:14:29.920282Z","shell.execute_reply.started":"2024-07-28T22:13:28.304523Z"},"id":"hmLKlPRwQEN7","trusted":true},"outputs":[],"source":["def get_op(x):\n","  sp = x.split('+')\n","  return [sp[0]] + sp[1].split('=')\n","\n","test_data, train_data = [], []\n","counter = [[0] * 21 for i in range(21)]\n","\n","max_for_test = 250\n","for i in lines:\n","  op = get_op(i)\n","  len_op = [len(op[0]), len(op[1])]\n","  if counter[len_op[0]][len_op[1]] < max_for_test:\n","    counter[len_op[0]][len_op[1]] += 1\n","    test_data.append(i)\n","  else:\n","    train_data.append(i)\n","\n","assert len(test_data) + len(train_data) == len(lines)\n","\n","random.shuffle(test_data)\n","random.shuffle(train_data)\n","del lines"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:15:20.381963Z","iopub.status.busy":"2024-07-28T22:15:20.381115Z","iopub.status.idle":"2024-07-28T22:15:25.536813Z","shell.execute_reply":"2024-07-28T22:15:25.535938Z","shell.execute_reply.started":"2024-07-28T22:15:20.381929Z"},"trusted":true},"outputs":[],"source":["model_name = \"numind/NuExtract-tiny\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model_config = AutoConfig.from_pretrained(model_name)\n","\n","model_config.bos_token_id = tokenizer.bos_token_id = 151644\n","model_config.eos_token_id = tokenizer.eos_token_id\n","model_config.pad_token_id = tokenizer.pad_token_id\n","assert model_config.eos_token_id == tokenizer.eos_token_id\n","assert model_config.bos_token_id == tokenizer.bos_token_id\n","assert model_config.pad_token_id == tokenizer.pad_token_id\n","print(tokenizer.bos_token, tokenizer.eos_token, tokenizer.pad_token)\n","tokenizer.padding_side = \"left\""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-28T22:15:42.958362Z","iopub.status.busy":"2024-07-28T22:15:42.957996Z","iopub.status.idle":"2024-07-28T22:22:24.639110Z","shell.execute_reply":"2024-07-28T22:22:24.638129Z","shell.execute_reply.started":"2024-07-28T22:15:42.958333Z"},"id":"J8YKIG4j78KY","outputId":"86a5e1d5-53e0-456d-b111-17c5bb1b1482","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5000000 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[151644, 18, 15, 20, 22, 20, 22, 20, 17, 22, 10, 18, 21, 20, 28, 21, 21, 15, 23, 20, 22, 20, 17, 22, 151646]\n","[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 21, 21, 15, 23, 20, 22, 20, 17, 22, 151646]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5000000/5000000 [06:34<00:00, 12666.89it/s]\n","  3%|▎         | 2845/100000 [00:00<00:06, 14329.99it/s]"]},{"name":"stdout","output_type":"stream","text":["[151644, 24, 16, 10, 23, 19, 17, 24, 18, 17, 22, 16, 18, 18, 19, 16, 24, 17, 28]\n","[22, 21, 17, 24, 18, 17, 22, 16, 18, 18, 19, 16, 24, 17, 151646]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100000/100000 [00:06<00:00, 14928.92it/s]\n"]}],"source":["class ArithmeticDataset(Dataset):\n","    def __init__(\n","        self,\n","        original_records: list,\n","        tokenizer: AutoTokenizer,\n","        add_global_bos: bool = True,\n","        add_global_eos: bool = True,\n","        labels_pad_token_id: int = -100,\n","        truncation_side: str = \"left\",\n","        train: bool = True\n","    ):\n","        self.original_records = original_records\n","        self.tokenizer = tokenizer\n","        self.labels_pad_token_id = labels_pad_token_id\n","        self.add_global_bos = add_global_bos\n","        self.add_global_eos = add_global_eos\n","        self.truncation_side = truncation_side\n","        self.is_printed = False\n","        self.train = train\n","\n","\n","        self.records = []\n","        for record in tqdm(original_records):\n","            tensors = self.convert_record(record)\n","            if tensors is None:\n","                continue\n","            self.records.append(tensors)\n","\n","    def __len__(self):\n","        return len(self.records)\n","\n","    def __getitem__(self, index):\n","        return self.records[index]\n","\n","    def get_tokens(self, text):\n","        return self.tokenizer.convert_tokens_to_ids([i for i in text])\n","\n","    def convert_record(self, record):\n","\n","        input_ids, labels = [], []\n","        input_ids = self.get_tokens(record)\n","        labels = input_ids.copy()\n","        \n","        idx = labels.index(self.tokenizer.convert_tokens_to_ids([\"=\"])[0])\n","        labels[:idx + 1] = [self.labels_pad_token_id] * (idx + 1)\n","\n","        if not input_ids:\n","            return None\n","\n","        if self.add_global_bos and input_ids[0] != self.tokenizer.bos_token_id:\n","            input_ids.insert(0, self.tokenizer.bos_token_id)\n","            labels.insert(0, self.labels_pad_token_id)\n","\n","        if self.add_global_eos and input_ids[-1] != self.tokenizer.eos_token_id:\n","            input_ids.append(self.tokenizer.eos_token_id)\n","            labels.append(self.tokenizer.eos_token_id)\n","        \n","        if not self.train:\n","            idx = input_ids.index(self.tokenizer.convert_tokens_to_ids([\"=\"])[0])\n","            labels = input_ids[idx + 1:]\n","            input_ids = input_ids[:idx + 1]\n","        if not self.is_printed:\n","            print(input_ids)\n","            print(labels)\n","            # print(\"Full prompt:\", self.tokenizer.decode(input_ids, skip_special_tokens=False))\n","            self.is_printed = True\n","\n","        input_ids = torch.LongTensor(input_ids)\n","        labels = torch.LongTensor(labels)\n","        attention_mask = input_ids.new_ones(input_ids.size())\n","        if self.train:\n","            assert input_ids.size(0) == labels.size(0) == attention_mask.size(0)\n","        return {\n","            \"input_ids\": input_ids,\n","            \"labels\": labels,\n","            \"attention_mask\": attention_mask\n","        }\n","\n","train_dataset = ArithmeticDataset(\n","    train_data[:int(5e6)],\n","    tokenizer\n",")\n","\n","test_dataset = ArithmeticDataset(\n","    test_data,\n","    tokenizer,\n","    train=False\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:23:01.438174Z","iopub.status.busy":"2024-07-28T22:23:01.437233Z","iopub.status.idle":"2024-07-28T22:23:01.442795Z","shell.execute_reply":"2024-07-28T22:23:01.441786Z","shell.execute_reply.started":"2024-07-28T22:23:01.438134Z"},"id":"CAT8aGzS_r61","trusted":true},"outputs":[],"source":["data_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=8)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:23:09.527414Z","iopub.status.busy":"2024-07-28T22:23:09.526553Z","iopub.status.idle":"2024-07-28T22:23:21.275265Z","shell.execute_reply":"2024-07-28T22:23:21.274309Z","shell.execute_reply.started":"2024-07-28T22:23:09.527376Z"},"id":"gJsMCX098gVE","trusted":true},"outputs":[],"source":["model = AutoModelForCausalLM.from_config(model_config)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:23:21.277203Z","iopub.status.busy":"2024-07-28T22:23:21.276918Z","iopub.status.idle":"2024-07-28T22:23:21.288693Z","shell.execute_reply":"2024-07-28T22:23:21.287678Z","shell.execute_reply.started":"2024-07-28T22:23:21.277179Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Qwen2ForCausalLM(\n","  (model): Qwen2Model(\n","    (embed_tokens): Embedding(151936, 1024, padding_idx=151643)\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:23:35.269273Z","iopub.status.busy":"2024-07-28T22:23:35.268905Z","iopub.status.idle":"2024-07-28T22:23:36.012843Z","shell.execute_reply":"2024-07-28T22:23:36.011929Z","shell.execute_reply.started":"2024-07-28T22:23:35.269245Z"},"id":"6KvkMhwTDV_7","trusted":true},"outputs":[{"data":{"text/plain":["Qwen2ForCausalLM(\n","  (model): Qwen2Model(\n","    (embed_tokens): Abacus(\n","      (embedding_layer): Embedding(151936, 1024, padding_idx=151643)\n","      (embedding): Embedding(50, 1024)\n","    )\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["class Abacus(torch.nn.Module):\n","    def __init__(self, digit_tokens, embedding_dim, embedding_layer, max_seq_length=1024, max_k=99):\n","        super().__init__()\n","        self.embedding_layer = embedding_layer\n","        self.embedding = torch.nn.Embedding(max_seq_length, embedding_dim)\n","        self.register_buffer(\"digits\", torch.tensor(digit_tokens), persistent=False)\n","\n","        self.max_k = max_k\n","\n","    def helper(self, mask, device):\n","        mask_shape = mask.shape\n","        \n","        shifted_mask = torch.cat([torch.zeros((mask_shape[0], 1), device=device, dtype=mask.dtype), mask[:, :-1]], dim=1)\n","        starts = (shifted_mask != mask) & mask\n","\n","        segment_ids = torch.cumsum(starts, dim=1)\n","\n","        index = torch.arange(mask.size(1)).repeat(mask.size(0), 1).to(device)\n","\n","        reset_index = torch.zeros_like(mask).long()\n","        second_term = index * starts.long()\n","        reset_index = reset_index.scatter_add(1, segment_ids, second_term)\n","\n","        positions = index - reset_index.gather(1, segment_ids) + 1\n","\n","        result = positions * mask\n","\n","        return result\n","\n","    def forward(self, input_ids):\n","        mask = torch.isin(input_ids, self.digits)\n","        output = self.helper(mask, input_ids.device)\n","\n","        k=0\n","        if self.training:\n","            k = random.randint(0, self.max_k)\n","            output[output>0] += k\n","        return self.embedding_layer(input_ids) + self.embedding(output)\n","\n","new_embed_layer = Abacus(tokenizer.convert_tokens_to_ids(['0','1','2','3','4','5','6','7','8','9']), 1024, model.model.embed_tokens, max_seq_length=50, max_k = 19)\n","model.model.embed_tokens = new_embed_layer\n","model.to(device)\n","model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T22:23:48.466893Z","iopub.status.busy":"2024-07-28T22:23:48.466036Z","iopub.status.idle":"2024-07-28T22:23:49.870360Z","shell.execute_reply":"2024-07-28T22:23:49.869369Z","shell.execute_reply.started":"2024-07-28T22:23:48.466850Z"},"id":"lf7SYudoXqU8","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]}],"source":["!mkdir /kaggle/working/train_dir"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-28T22:24:35.216140Z","iopub.status.busy":"2024-07-28T22:24:35.215486Z","iopub.status.idle":"2024-07-28T22:24:35.248877Z","shell.execute_reply":"2024-07-28T22:24:35.247952Z","shell.execute_reply.started":"2024-07-28T22:24:35.216103Z"},"id":"Hz9EkVS5W50g","outputId":"4537995f-e8f8-41c5-ecf0-629a792bbafc","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_args = TrainingArguments(\n","  output_dir = '/kaggle/working/train_dir',\n","  evaluation_strategy = 'no',\n","  learning_rate=1e-4,\n","  weight_decay=0.001,\n","  num_train_epochs=1,\n","#   max_steps=12000,\n","  lr_scheduler_type='cosine',\n","  save_steps=1000,\n","  save_total_limit=1,\n","  seed=random_state,\n","  report_to='none',\n","  auto_find_batch_size = True,\n","  use_cpu = False\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"execution":{"iopub.execute_input":"2024-07-28T22:24:46.400559Z","iopub.status.busy":"2024-07-28T22:24:46.399869Z","iopub.status.idle":"2024-07-28T22:24:46.419172Z","shell.execute_reply":"2024-07-28T22:24:46.418437Z","shell.execute_reply.started":"2024-07-28T22:24:46.400527Z"},"id":"hQOdk-2zZ0an","outputId":"8df681d6-373b-4593-89ab-0e5b842a373b","trusted":true},"outputs":[],"source":["trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        data_collator=data_collator\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"execution":{"iopub.execute_input":"2024-07-28T22:24:48.844088Z","iopub.status.busy":"2024-07-28T22:24:48.843370Z","iopub.status.idle":"2024-07-28T23:10:01.038233Z","shell.execute_reply":"2024-07-28T23:10:01.036799Z","shell.execute_reply.started":"2024-07-28T22:24:48.844056Z"},"id":"pELQtRPqeCQK","outputId":"fa9894f0-3ce1-4f97-ad7f-1126508519cf","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8001' max='625000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  8001/625000 44:44 < 57:31:35, 2.98 it/s, Epoch 0.01/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.429900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.182200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>2.173700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>2.172400</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>2.164500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>2.163500</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>2.169100</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>2.161200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>2.159900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>2.160600</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>2.159500</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>2.161700</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>2.158800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>2.157400</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>2.154700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/memory.py:144\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2796\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2796\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2879\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 2879\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2880\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[1;32m   2881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2995\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   2990\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   2991\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   2992\u001b[0m     )\n\u001b[1;32m   2993\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2994\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 2995\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2997\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   2998\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   2999\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   3000\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-28T23:25:27.661792Z","iopub.status.busy":"2024-07-28T23:25:27.660991Z","iopub.status.idle":"2024-07-28T23:25:28.292363Z","shell.execute_reply":"2024-07-28T23:25:28.291346Z","shell.execute_reply.started":"2024-07-28T23:25:27.661756Z"},"id":"MsXaCPwTwbVU","outputId":"30b6b04b-9f4d-417d-82ea-e4661ff57bb2","trusted":true},"outputs":[{"data":{"text/plain":["Qwen2ForCausalLM(\n","  (model): Qwen2Model(\n","    (embed_tokens): Abacus(\n","      (embedding_layer): Embedding(151936, 1024, padding_idx=151643)\n","      (embedding): Embedding(50, 1024)\n","    )\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["from safetensors.torch import load_model, save_model\n","\n","load_model(model, \"/kaggle/working/train_dir/checkpoint-7000/model.safetensors\")\n","model.eval()\n","model.to(device)"]},{"cell_type":"code","execution_count":38,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-28T23:36:12.131937Z","iopub.status.busy":"2024-07-28T23:36:12.130907Z","iopub.status.idle":"2024-07-28T23:36:12.149062Z","shell.execute_reply":"2024-07-28T23:36:12.147940Z","shell.execute_reply.started":"2024-07-28T23:36:12.131879Z"},"id":"sLNslovb7x-Q","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["Qwen2ForCausalLM(\n","  (model): Qwen2Model(\n","    (embed_tokens): Abacus(\n","      (embedding_layer): Embedding(151936, 1024, padding_idx=151643)\n","      (embedding): Embedding(50, 1024)\n","    )\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",")"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["dp = IterableWrapper(test_dataset[:10000])\n","dp = dp.batch(batch_size=8, wrapper_class=data_collator)\n","model.eval() \n","model.to(device)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T23:36:14.497623Z","iopub.status.busy":"2024-07-28T23:36:14.496953Z","iopub.status.idle":"2024-07-28T23:36:14.507881Z","shell.execute_reply":"2024-07-28T23:36:14.506864Z","shell.execute_reply.started":"2024-07-28T23:36:14.497588Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GenerationConfig {\n","  \"bos_token_id\": 151644,\n","  \"eos_token_id\": 151646,\n","  \"max_new_tokens\": 100,\n","  \"pad_token_id\": 151643,\n","  \"use_cache\": false\n","}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["generation_config = {\n","  \"_from_model_config\": True,\n","  \"bos_token_id\": tokenizer.bos_token_id,\n","  \"eos_token_id\": tokenizer.eos_token_id,\n","  \"pad_token_id\": tokenizer.pad_token_id,\n","  \"transformers_version\": \"4.42.4\",\n","  \"max_new_tokens\": 100,\n","  \"use_cache\": False\n","}\n","\n","with open('/kaggle/working/generation_config.json', 'w') as fp:\n","    json.dump(generation_config, fp)\n","\n","generation_config = GenerationConfig.from_pretrained(pretrained_model_name=model_name, config_file_name='/kaggle/working/generation_config.json')\n","generation_config"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T23:37:24.213961Z","iopub.status.busy":"2024-07-28T23:37:24.213054Z","iopub.status.idle":"2024-07-28T23:37:24.223445Z","shell.execute_reply":"2024-07-28T23:37:24.222594Z","shell.execute_reply.started":"2024-07-28T23:37:24.213924Z"},"trusted":true},"outputs":[],"source":["def convert_to_list(x, from_model=True):\n","    x = x.cpu().tolist()\n","    res = []\n","    for i in x:\n","        l = 0\n","        while i[l] in [tokenizer.pad_token_id, tokenizer.bos_token_id, -100]:\n","            l += 1\n","        r = len(i) - 1\n","        while i[r] == tokenizer.pad_token_id and r > l:\n","            r -= 1\n","        res.append(i[l:r + 1])\n","    if from_model:\n","        return [i[i.index(tokenizer.convert_tokens_to_ids([\"=\"])[0]) + 1:] for i in res]   \n","    return res\n","        \n","def compute_metric(x, labels):\n","    assert len(x) == len(labels)\n","    x, labels = convert_to_list(x), convert_to_list(labels, from_model=False)\n","    res = 0\n","    for i, j in zip(x, labels):\n","        if len(i) != len(j):\n","            continue\n","        for k in range(len(i)):\n","            if i[k] != j[k]:\n","                break\n","            if k == len(i) - 1:\n","                res += 1\n","    return res"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T23:37:28.593328Z","iopub.status.busy":"2024-07-28T23:37:28.592523Z","iopub.status.idle":"2024-07-29T00:06:14.892913Z","shell.execute_reply":"2024-07-29T00:06:14.891878Z","shell.execute_reply.started":"2024-07-28T23:37:28.593293Z"},"id":"3bqi83ZN-4cB","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [28:46<00:00,  1.38s/it]\n"]}],"source":["res = 0\n","for batch in tqdm(dp):\n","    with torch.no_grad():\n","        output = model.generate(input_ids=batch[\"input_ids\"].to(device),generation_config=generation_config)\n","        a = compute_metric(output, batch[\"labels\"])\n","        res += a"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T00:43:59.176369Z","iopub.status.busy":"2024-07-29T00:43:59.176013Z","iopub.status.idle":"2024-07-29T00:43:59.181148Z","shell.execute_reply":"2024-07-29T00:43:59.180296Z","shell.execute_reply.started":"2024-07-29T00:43:59.176340Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy = 0.0513\n"]}],"source":["print(\"Accuracy =\", res / 1e4)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5457631,"sourceId":9051608,"sourceType":"datasetVersion"},{"modelId":95608,"modelInstanceId":70557,"sourceId":84009,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
